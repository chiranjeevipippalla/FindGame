{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 510 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n",
      "Found 30 images belonging to 3 classes.\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022988750510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000022988750510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002298875CBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002298875CBF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "4/4 - 4s - loss: 1.6775 - accuracy: 0.4750 - val_loss: 1.8699 - val_accuracy: 0.4500\n",
      "Epoch 2/40\n",
      "4/4 - 2s - loss: 1.7495 - accuracy: 0.3750 - val_loss: 1.4533 - val_accuracy: 0.4500\n",
      "Epoch 3/40\n",
      "4/4 - 2s - loss: 1.4010 - accuracy: 0.4500 - val_loss: 1.7720 - val_accuracy: 0.2500\n",
      "Epoch 4/40\n",
      "4/4 - 2s - loss: 1.5655 - accuracy: 0.4250 - val_loss: 1.2298 - val_accuracy: 0.5000\n",
      "Epoch 5/40\n",
      "4/4 - 2s - loss: 1.5742 - accuracy: 0.5000 - val_loss: 1.4841 - val_accuracy: 0.4500\n",
      "Epoch 6/40\n",
      "4/4 - 2s - loss: 1.5270 - accuracy: 0.4750 - val_loss: 1.7583 - val_accuracy: 0.3000\n",
      "Epoch 7/40\n",
      "4/4 - 2s - loss: 1.6475 - accuracy: 0.4250 - val_loss: 1.1563 - val_accuracy: 0.5500\n",
      "Epoch 8/40\n",
      "4/4 - 2s - loss: 0.9580 - accuracy: 0.5750 - val_loss: 1.2781 - val_accuracy: 0.6000\n",
      "Epoch 9/40\n",
      "4/4 - 2s - loss: 1.1031 - accuracy: 0.5250 - val_loss: 1.3397 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "4/4 - 2s - loss: 1.0819 - accuracy: 0.5000 - val_loss: 1.6635 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "4/4 - 2s - loss: 1.2918 - accuracy: 0.5250 - val_loss: 1.3346 - val_accuracy: 0.6000\n",
      "Epoch 12/40\n",
      "4/4 - 2s - loss: 1.0727 - accuracy: 0.5500 - val_loss: 0.7391 - val_accuracy: 0.6000\n",
      "Epoch 13/40\n",
      "4/4 - 2s - loss: 1.0192 - accuracy: 0.5500 - val_loss: 1.0584 - val_accuracy: 0.6000\n",
      "Epoch 14/40\n",
      "4/4 - 2s - loss: 1.0925 - accuracy: 0.5750 - val_loss: 0.5535 - val_accuracy: 0.7000\n",
      "Epoch 15/40\n",
      "4/4 - 2s - loss: 0.6848 - accuracy: 0.7000 - val_loss: 0.8086 - val_accuracy: 0.6500\n",
      "Epoch 16/40\n",
      "4/4 - 2s - loss: 0.8112 - accuracy: 0.6000 - val_loss: 0.7735 - val_accuracy: 0.6500\n",
      "Epoch 17/40\n",
      "4/4 - 2s - loss: 1.0603 - accuracy: 0.5750 - val_loss: 0.7849 - val_accuracy: 0.6500\n",
      "Epoch 18/40\n",
      "4/4 - 2s - loss: 0.6441 - accuracy: 0.7250 - val_loss: 0.9492 - val_accuracy: 0.6000\n",
      "Epoch 19/40\n",
      "4/4 - 2s - loss: 0.8001 - accuracy: 0.5750 - val_loss: 0.4423 - val_accuracy: 0.9000\n",
      "Epoch 20/40\n",
      "4/4 - 2s - loss: 0.6912 - accuracy: 0.6750 - val_loss: 0.8926 - val_accuracy: 0.6500\n",
      "Epoch 21/40\n",
      "4/4 - 2s - loss: 1.0041 - accuracy: 0.6750 - val_loss: 0.7329 - val_accuracy: 0.7000\n",
      "Epoch 22/40\n",
      "4/4 - 2s - loss: 0.4658 - accuracy: 0.8000 - val_loss: 0.5290 - val_accuracy: 0.6500\n",
      "Epoch 23/40\n",
      "4/4 - 2s - loss: 0.4990 - accuracy: 0.7750 - val_loss: 0.4632 - val_accuracy: 0.7500\n",
      "Epoch 24/40\n",
      "4/4 - 2s - loss: 0.6800 - accuracy: 0.6250 - val_loss: 0.4982 - val_accuracy: 0.7500\n",
      "Epoch 25/40\n",
      "4/4 - 2s - loss: 0.4042 - accuracy: 0.7750 - val_loss: 0.6299 - val_accuracy: 0.7500\n",
      "Epoch 26/40\n",
      "4/4 - 2s - loss: 0.5627 - accuracy: 0.7250 - val_loss: 0.6113 - val_accuracy: 0.6500\n",
      "Epoch 27/40\n",
      "4/4 - 2s - loss: 0.4625 - accuracy: 0.8250 - val_loss: 0.3078 - val_accuracy: 0.9000\n",
      "Epoch 28/40\n",
      "4/4 - 2s - loss: 0.6695 - accuracy: 0.7750 - val_loss: 0.5378 - val_accuracy: 0.7000\n",
      "Epoch 29/40\n",
      "4/4 - 2s - loss: 0.5375 - accuracy: 0.7250 - val_loss: 0.6255 - val_accuracy: 0.7000\n",
      "Epoch 30/40\n",
      "4/4 - 2s - loss: 0.5965 - accuracy: 0.7250 - val_loss: 0.3925 - val_accuracy: 0.8500\n",
      "Epoch 31/40\n",
      "4/4 - 2s - loss: 0.4576 - accuracy: 0.7750 - val_loss: 0.3370 - val_accuracy: 0.8500\n",
      "Epoch 32/40\n",
      "4/4 - 2s - loss: 0.5374 - accuracy: 0.7750 - val_loss: 0.6646 - val_accuracy: 0.7000\n",
      "Epoch 33/40\n",
      "4/4 - 2s - loss: 0.3131 - accuracy: 0.9250 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
      "Epoch 34/40\n",
      "4/4 - 2s - loss: 0.6818 - accuracy: 0.7000 - val_loss: 0.2715 - val_accuracy: 0.9000\n",
      "Epoch 35/40\n",
      "4/4 - 2s - loss: 0.5398 - accuracy: 0.8000 - val_loss: 0.2676 - val_accuracy: 0.9500\n",
      "Epoch 36/40\n",
      "4/4 - 2s - loss: 0.4778 - accuracy: 0.7250 - val_loss: 0.6229 - val_accuracy: 0.7000\n",
      "Epoch 37/40\n",
      "4/4 - 2s - loss: 0.5956 - accuracy: 0.8000 - val_loss: 0.7786 - val_accuracy: 0.6000\n",
      "Epoch 38/40\n",
      "4/4 - 2s - loss: 0.4945 - accuracy: 0.7750 - val_loss: 0.3089 - val_accuracy: 0.9000\n",
      "Epoch 39/40\n",
      "4/4 - 2s - loss: 0.6150 - accuracy: 0.8250 - val_loss: 0.3778 - val_accuracy: 0.7500\n",
      "Epoch 40/40\n",
      "4/4 - 2s - loss: 0.2690 - accuracy: 0.9250 - val_loss: 0.5035 - val_accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "train_path = 'datasets/train'\n",
    "valid_path = 'datasets/valid'\n",
    "test_path = 'datasets/test'\n",
    "\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size=(224,224), classes=['apples', 'bananas', 'oranges'], batch_size=2)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size=(224,224), classes=['apples', 'bananas', 'oranges'], batch_size=2)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224), classes=['apples', 'bananas', 'oranges'], batch_size=2, shuffle=False)\n",
    "\n",
    "mobile_model = tf.keras.applications.mobilenet.MobileNet()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in mobile_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "    \n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_batches, steps_per_epoch=4, validation_data=valid_batches, validation_steps=4, epochs=40, verbose=2)\n",
    "\n",
    "keras_file = \"mobilenet_model.h5\"\n",
    "tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
